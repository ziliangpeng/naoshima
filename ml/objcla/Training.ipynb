{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8325d201-841f-4730-86d8-fd447729f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import click\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import dataloader\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "import importlib\n",
    "\n",
    "import tf_models  # First, import the library\n",
    "importlib.reload(tf_models)  # Now, reload it\n",
    "from tf_models import *\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "\n",
    "dataset = 'cifar10'\n",
    "\n",
    "def make_tb(name):\n",
    "    prefix = name\n",
    "    log_dir = os.path.join(\n",
    "        \"logs\", prefix + \"-\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    )\n",
    "    return tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir, histogram_freq=1, update_freq=\"batch\"\n",
    "    )\n",
    "\n",
    "loader = getattr(dataloader, f\"load_{dataset}\")\n",
    "x_train, y_train, x_test, y_test = loader(onehot=True)\n",
    "\n",
    "if x_train[0].ndim == 2:\n",
    "    x_train = x_train[..., np.newaxis]\n",
    "    x_test = x_test[..., np.newaxis]\n",
    "image_shape = x_train[0].shape  # (28, 28)\n",
    "\n",
    "model = ResNet(image_shape, num_classes=y_train.shape[1], l2_lambda=4e-3, augmentation=True)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=CategoricalCrossentropy(), metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.load_weights(f'{dataset}-viz.keras', skip_mismatch=True)\n",
    "logger.info('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db4b3e2-0768-4aa4-8739-6d241af9f6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc08d8d-a472-4422-a4bb-b946abfa2a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = 'prod'\n",
    "\n",
    "if stage == 'test':\n",
    "    iter = 4\n",
    "    epo = 8\n",
    "else:\n",
    "    iter = 2\n",
    "    epo = 100\n",
    "for i in range(iter):\n",
    "    with tf.device(\"/GPU:0\"):\n",
    "        history = model.fit(\n",
    "            x_train, y_train, epochs=epo, batch_size=64, \n",
    "            # validation_split=0.02,\n",
    "            validation_data=(x_test, y_test),\n",
    "            callbacks=[make_tb(\"nb-resnet-\" + dataset + \"-augmented\")],\n",
    "        )\n",
    "        model.save(f'{dataset}-viz.keras')\n",
    "        logger.info(\"saved model\")\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    loss, accuracy = model.evaluate(x_test, y_test)\n",
    "    logger.info(f\"iter {i}\")\n",
    "    logger.info(f\"Test loss: {loss:.4f}\")\n",
    "    logger.info(f\"Test accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c571a02c-fab9-4641-b2d0-075f82114276",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'{dataset}-viz.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6006400f-969c-4423-950a-fcb8f20022dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(f'{dataset}-viz.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
